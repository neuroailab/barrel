\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage{nips_2017}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{amsmath, amssymb, amsthm, epsfig}

\usepackage{enumitem}
\setlist[itemize]{leftmargin=-5ex}
\setlist[itemize]{itemsep=-1ex}

\title{Toward Goal-Driven Neural Network Models for Rodent Whisker-Trigeminal System}

\author{
Chengxu Zhuang\\
Department of Psychology\\
Stanford University\\
Stanford, CA 94305 \\
\texttt{chengxuz@stanford.edu} \\
\And
Jonas Kubilius \\
Department of Brain and Cognitive Sciences \\
Massachusetts Institute of Technology \\
Cambridge, MA  02139\\
\texttt{qbilius@mit.edu} \\
\And
Mitra Hartmann \\
Departments of Biomedical Engineering \\
and Mechanical Engineering \\
Northwestern University \\
Evanston, IL  60208\\
\texttt{hartmann@northwestern.edu} \\
\And
Daniel Yamins \\
Departments of Psychology and Computer Science \\
Stanford Neurosciences Institute \\
Stanford University \\
Stanford, CA 94305 \\
\texttt{yamins@stanford.edu} \\
}


\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
In large part, rodents ``see'' the world through their whiskers, a powerful sense enabled by a series of brain areas called the whisker-trigeminal system. 
Raw data arrives in the form of mechanical input to the exquisitely sensitive, actively-controllable whisker array, and is processed up through a hierarchy of neural circuits, eventually arriving in cortical regions that communicate with decision-making and memory areas.
Although a long history of experimental studies has characterized many aspects of these processing stages, the computational operations in whisker-trigeminal system, especially further downstream of the sensor, remain largely unknown.
In this work, we take a \emph{goal-driven} deep neural network (DNN) approach to modeling these computations.
First, we construct a biophysically-realistic model of the rat whisker array.  
We then generate a large-scale data of whisker sweeps across a wide variety of 3D objects in highly-varying poses, angles, and speeds.
Next, we train DNNs from several distinct architectural families to solve a shape recognition task in this dataset. 
Each architectural family represents a structurally-distinct hypothesis for processing in the whisker-trigeminal system,  corresponding different ways in which spatial and temporal information can be integrated.
We find that most networks perform poorly on the challenging shape recognition task, but that specific architectures from several families can achieve reasonable performance levels.
Finally, we show that using Representational Dissimilarity Matrices (RDMs), a tool for comparing population codes between neural systems, we can separate these higher-performing networks with data of a type that could plausibly be collected in a neurophysiology experiment.
Our results are a proof-of-concept that goal-driven DNN networks of the whisker-trigeminal system are potentially within reach.
\end{abstract}

%Papers may be only up to eight pages long, including figures.
%An additional ninth page containing only cited references is allowed.

\section{Introduction} %~750 words
\input{intro.tex}

\section{Modeling the Whisker Array Sensor} %~500 words
\input{whisk_model.tex}

\section{A Large-Scale Whisker Sweep Dataset} %~750 words
\input{dataset.tex}

\section{Computational Architectures} %~1250 words
\input{archi.tex}

\section{Results} %~500 words
\input{results.tex}

\section{Conclusion}  %~250 words
\input{conclusion.tex}

%\begin{figure}[h]
%\centering
%\includegraphics [width=1\linewidth]{figures/model_class.pdf}
%\vspace{-2mm}
%\caption{\textbf{(a)} Figure caption~\label{figname}}
%\end{figure}


{\small
\bibliography{refs}}
\bibliographystyle{plain}

\end{document}
