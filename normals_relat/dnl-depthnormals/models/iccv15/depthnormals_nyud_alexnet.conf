[config]
imports = numpy as np

[train]
resumptive = True
learning_rate = 1
bsize = 32
momentum = 0.9
#lrate_sched = ((350, 1.0), (100, 0.1), (51, 0.001))
evaluate_epochs = 10
save_stats_epochs = 10
checkpoint_all_freq = 50
scale2_size = (55, 74)
scale3_size = (109, 147)

[data]
depth_space = log
zero_mean_depths = False
divide_std_depths = True

[init]

[load]

[full1]
type = full
load_key = coarse
noutput = 4096
init_W = lambda shp: 0.01*np.random.randn(*shp)
bias = True
weight_decay_W = 1e-5
learning_rate_scale = 0.1

[full2]
type = full
load_key = coarse
noutput = 17024
feature_size = (64, 14, 19)
#init_w = lambda shp: 0.01*(np.random.rand(*shp)-0.5)
init_w = lambda shp: 0.001*np.random.randn(*shp)
bias = True
weight_decay_W = 1e-5
learning_rate_scale = 0.1

[depths_bias]
type = full
load_key = coarse
noutput = 4070
init_w = lambda shp: np.zeros(shp)
bias = True
learning_rate_scale = 0.1

[conv_s2_1]
type = conv
load_key = fine_2
filter_shape = (96,3,9,9)
stride = 2
init_w = lambda shp: 0.001*np.random.randn(*shp)
init_b = 0.0
conv_mode = valid
weight_decay_w = 0.0001
learning_rate_scale = 0.001

[pool_s2_1]
type = maxpool
poolsize = (3,3)
poolstride = (2,2)

[depths_conv_s2_2]
type = conv
load_key = fine_2
filter_shape = (64,160,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[depths_conv_s2_3]
type = conv
load_key = fine_2
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[depths_conv_s2_4]
type = conv
load_key = fine_2
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[depths_conv_s2_5]
type = conv
load_key = fine_2
filter_shape = (64,1,5,5)
transpose = True
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.001

[normals_conv_s2_2]
type = conv
load_key = fine_2
filter_shape = (64,160,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[normals_conv_s2_3]
type = conv
load_key = fine_2
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[normals_conv_s2_4]
type = conv
load_key = fine_2
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[normals_conv_s2_5]
type = conv
load_key = fine_2
filter_shape = (64,3,5,5)
transpose = True
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.001


# finer scale 3

[conv_s3_1]
type = conv
load_key = fine_3
filter_shape = (64,3,9,9)
stride = 2
init_w = lambda shp: 0.001*np.random.randn(*shp)
init_b = 0.0
conv_mode = valid
weight_decay_w = 0.0001
learning_rate_scale = 0.001

[pool_s3_1]
type = maxpool
poolsize = (3,3)
poolstride = (1,1)

[depths_conv_s3_2]
type = conv
load_key = fine_3
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[depths_conv_s3_3]
type = conv
load_key = fine_3
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[depths_conv_s3_4]
type = conv
load_key = fine_3
filter_shape = (64,1,5,5)
transpose = True
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.001

[normals_conv_s3_2]
type = conv
load_key = fine_3
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[normals_conv_s3_3]
type = conv
load_key = fine_3
filter_shape = (64,64,5,5)
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.01

[normals_conv_s3_4]
type = conv
load_key = fine_3
filter_shape = (64,3,5,5)
transpose = True
init_w = lambda shp: 0.01*np.random.randn(*shp)
init_b = 0.0
conv_mode = same
weight_decay_w = 0.0001
learning_rate_scale = 0.001


# imnet stack for coarse scale

[imnet_conv1]
type = conv
load_key = imagenet
filter_shape = (96, 3, 11, 11)
stride = 4
conv_mode = valid
init_w = lambda shp: 0.01*np.random.randn(*shp)
learning_rate_scale = 0.001
weight_decay_w = 0.0005

[imnet_pool1]
type = maxpool
load_key = imagenet
poolsize = (3,3)
poolstride = (2,2)

[imnet_conv2]
type = conv
load_key = imagenet
filter_shape = (256, 96, 5, 5)
conv_mode = same
stride = 1
init_w = lambda shp: 0.01*np.random.randn(*shp)
learning_rate_scale = 0.001
weight_decay_w = 0.0005

[imnet_pool2]
type = maxpool
load_key = imagenet
poolsize = (3,3)
poolstride = (2,2)

[imnet_conv3]
type = conv
load_key = imagenet
filter_shape = (384, 256, 3, 3)
conv_mode = same
stride = 1
init_w = lambda shp: 0.01*np.random.randn(*shp)
learning_rate_scale = 0.001
weight_decay_w = 0.0005

[imnet_conv4]
type = conv
load_key = imagenet
filter_shape = (384, 384, 3, 3)
conv_mode = same
stride = 1
init_w = lambda shp: 0.01*np.random.randn(*shp)
learning_rate_scale = 0.001
weight_decay_w = 0.0005

[imnet_conv5]
type = conv
load_key = imagenet
filter_shape = (256, 384, 3, 3)
conv_mode = same
stride = 1
init_w = lambda shp: 0.01*np.random.randn(*shp)
learning_rate_scale = 0.001
weight_decay_w = 0.0005

[imnet_pool5]
type = maxpool
load_key = imagenet
poolsize = (3,3)
poolstride = (2,2)

