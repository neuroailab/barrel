% scibib.bib

% This is the .bib file used to compile the document "A simple Science
% template" (scifile.tex).  It is not intended as an example of how to
% set up your BibTeX file.




@article{yamins2016using,
  title={Using goal-driven deep learning models to understand sensory cortex},
  author={Yamins, Daniel LK and DiCarlo, James J},
  journal={Nature neuroscience},
  volume={19},
  number={3},
  pages={356--365},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{felleman1991distributed,
  title={Distributed hierarchical processing in the primate cerebral cortex},
  author={Felleman, Daniel J and Van Essen, David C},
  journal={Cerebral cortex},
  volume={1},
  number={1},
  pages={1--47},
  year={1991},
  publisher={Oxford Univ Press}
}

@article{riesenhuber1999hierarchical,
  title={Hierarchical models of object recognition in cortex},
  author={Riesenhuber, Maximilian and Poggio, Tomaso},
  journal={Nature neuroscience},
  volume={2},
  number={11},
  pages={1019--1025},
  year={1999},
  publisher={Nature Publishing Group}
}

@article{serre2007feedforward,
  title={A feedforward architecture accounts for rapid categorization},
  author={Serre, Thomas and Oliva, Aude and Poggio, Tomaso},
  journal={Proceedings of the National Academy of Sciences},
  volume={104},
  number={15},
  pages={6424--6429},
  year={2007},
  publisher={National Acad Sciences}
}

@article{fukushima1980neocognitron,
  title={Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position},
  author={Fukushima, Kunihiko},
  journal={Biological cybernetics},
  volume={36},
  number={4},
  pages={193--202},
  year={1980},
  publisher={Springer}
}

@article{bengio2009learning,
  title={Learning deep architectures for AI},
  author={Bengio, Yoshua},
  journal={Foundations and trends{\textregistered} in Machine Learning},
  volume={2},
  number={1},
  pages={1--127},
  year={2009},
  publisher={Now Publishers Inc.}
}

@article{pinto2009high,
  title={A high-throughput screening approach to discovering good forms of biologically inspired visual representation},
  author={Pinto, Nicolas and Doukhan, David and DiCarlo, James J and Cox, David D},
  journal={PLoS Comput Biol},
  volume={5},
  number={11},
  pages={e1000579},
  year={2009},
  publisher={Public Library of Science}
}

@article{Iwamura1998,
abstract = {Recent studies of the postcentral and additional somatosensory cortices support a hierarchical scheme for information processing. In the postcentral gyrus, the complexity of receptive field properties increases with caudal progression from area 1. It has been reported that the anterior bank of the intraparietal sulcus, the caudalmost part of the postcentral gyrus, is responsible for the systematic integration of bilateral body paris, as well as of somatic and visual information.},
author = {Iwamura, Yoshiaki},
doi = {10.1016/S0959-4388(98)80041-X},
file = {:Users/chengxuz/Documents/1-s2.0-S095943889880041X-main.pdf:pdf},
isbn = {0959-4388 (Print)$\backslash$n0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {4},
pages = {522--528},
pmid = {9751655},
title = {{Hierarchical somatosensory processing}},
volume = {8},
year = {1998}
}
@article{Towal2011,
abstract = {In all sensory modalities, the data acquired by the nervous system is shaped by the biomechanics, material properties, and the morphology of the peripheral sensory organs. The rat vibrissal (whisker) system is one of the premier models in neuroscience to study the relationship between physical embodiment of the sensor array and the neural circuits underlying perception. To date, however, the three-dimensional morphology of the vibrissal array has not been characterized. Quantifying array morphology is important because it directly constrains the mechanosensory inputs that will be generated during behavior. These inputs in turn shape all subsequent neural processing in the vibrissal-trigeminal system, from the trigeminal ganglion to primary somatosensory ("barrel") cortex. Here we develop a set of equations for the morphology of the vibrissal array that accurately describes the location of every point on every whisker to within Â±5//{\%} of the whisker length. Given only a whisker's identity (row and column location within the array), the equations establish the whisker's two-dimensional (2D) shape as well as three-dimensional (3D) position and orientation. The equations were developed via parameterization of 2D and 3D scans of six rat vibrissal arrays, and the parameters were specifically chosen to be consistent with those commonly measured in behavioral studies. The final morphological model was used to simulate the contact patterns that would be generated as a rat uses its whiskers to tactually explore objects with varying curvatures. The simulations demonstrate that altering the morphology of the array changes the relationship between the sensory signals acquired and the curvature of the object. The morphology of the vibrissal array thus directly constrains the nature of the neural computations that can be associated with extraction of a particular object feature. These results illustrate the key role that the physical embodiment of the sensor array plays in the sensing process. ------------------------------------- Whisker mechanics Very extensive and boring description of whiskers. Simulation of whisker contact during whisking with objects displaying different curvature.},
author = {Towal, R. Blythe and Quist, Brian W. and Gopal, Venkatesh and Solomon, Joseph H. and Hartmann, Mitra J Z},
doi = {10.1371/journal.pcbi.1001120},
file = {:Users/chengxuz/Documents/towal{\_}plos{\_}2011.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {4},
pmid = {21490724},
title = {{The morphology of the rat vibrissal array: A model for quantifying spatiotemporal patterns of whisker-object contact}},
volume = {7},
year = {2011}
}
@article{Boubenec2012,
abstract = {Rats use their whiskers to extract a wealth of information about their immediate environment, such as the shape, position or texture of an object. The information is conveyed to mechanoreceptors located within the whisker follicle in the form of a sequence of whisker deflections induced by the whisker/object contact interaction. How the whiskers filter and shape the mechanical information and effectively participate in the coding of tactile features remains an open question to date. In the present article, a biomechanical model was developed that provides predictions of the whisker dynamics during active tactile exploration, amenable to quantitative experimental comparison. This model is based on a decomposition of the whisker profile into a slow, quasi-static sequence and rapid resonant small-scale vibrations. It was applied to the typical situation of a rat actively whisking across a solid object. Having derived the quasi-static sequence of whisker deformation, the resonant properties of the whisker were analyzed, taking into account the boundary conditions imposed by the whisker/surface contact. We then focused on two elementary mechanical events that are expected to trigger significant neural responses, namely (1) the whisker/object first contact and (2) the whisker detachment from the object. Both events were found to trigger a deflection wave propagating upward to the mystacial pad at constant velocity of â‰ˆ3-5 m/s. This yielded a characteristic mechanical signature at the whisker base, in the form of a large peak of negative curvature occurring â‰ˆ4 ms after the event has been triggered. The dependence in amplitude and lag of this mechanical signal with the main contextual parameters (such as radial or angular distance) was investigated. The model was validated experimentally by comparing its predictions to high-speed video recordings of shock-induced whisker deflections performed on anesthetized rats. The consequences of these results on possible tactile encoding schemes are briefly discussed.},
author = {Boubenec, Yves and Shulz, Daniel E and Debr{\'{e}}geas, Georges},
doi = {10.3389/fnbeh.2012.00074},
file = {:Users/chengxuz/Documents/fnbeh-06-00074.pdf:pdf},
issn = {1662-5153},
journal = {Front Behav Neurosci},
keywords = {exploration,exploration, rat, resonance, tactile, vibration, v,rat,resonance,tactile,vibration,vibrissae,whiskers,whisking},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {November},
pages = {74},
pmid = {23133410},
title = {{Whisker encoding of mechanical events during active tactile exploration.}},
url = {http://dx.doi.org/10.3389/fnbeh.2012.00074},
volume = {6},
year = {2012}
}
@article{Diamond2008,
abstract = {In the visual system of primates, different neuronal pathways are specialized for processing information about the spatial coordinates of objects and their identity - that is, 'where' and 'what'. By contrast, rats and other nocturnal animals build up a neuronal representation of 'where' and 'what' by seeking out and palpating objects with their whiskers. We present recent evidence about how the brain constructs a representation of the surrounding world through whisker-mediated sense of touch. While considerable knowledge exists about the representation of the physical properties of stimuli - like texture, shape and position - we know little about how the brain represents their meaning. Future research may elucidate this and show how the transformation of one representation to another is achieved.},
author = {Diamond, Mathew E and von Heimendahl, Moritz and Knutsen, Per Magne and Kleinfeld, David and Ahissar, Ehud},
doi = {10.1038/nrn2411},
file = {:Users/chengxuz/Documents/nrn2411.pdf:pdf},
isbn = {1471-003x},
issn = {1471-003X},
journal = {Nat Rev Neurosci},
keywords = {Action Potentials,Afferent,Animal,innervation/physiology,physiology; Afferent Pathways,physiology; Animals; Behavior,physiology; Head Movements,physiology; Mechanoreceptors,physiology; Neurons,physiology; Rats; Somatosensory Cortex,physiology; Space Perception,physiology; Touch,physiology; Trigeminal Nerve,physiology; Vibrissae},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {8},
pages = {601--612},
pmid = {18641667},
title = {{'Where' and 'what' in the whisker sensorimotor system.}},
url = {http://dx.doi.org/10.1038/nrn2411},
volume = {9},
year = {2008}
}
@article{Arabzadeh2005,
abstract = {A major challenge of sensory systems neuroscience is to quantify brain activity underlying perceptual experiences and to explain this activity as the outcome of elemental neuronal response properties. Rats make extremely fine discriminations of texture by "whisking" their vibrissae across an object's surface, yet the neuronal coding underlying texture sensations remains unknown. Measuring whisker vibrations during active whisking across surfaces, we found that each texture results in a unique "kinetic signature" defined by the temporal profile of whisker velocity. We presented these texture-induced vibrations as stimuli while recording responses of first-order sensory neurons and neurons in the whisker area of cerebral cortex. Each texture is encoded by a distinctive, temporally precise firing pattern. To look for the neuronal coding properties that give rise to texture-specific firing patterns, we delivered horizontal and vertical whisker movements that varied randomly in time ("white noise") and found that the response probabilities of first-order neurons and cortical neurons vary systematically according to whisker speed and direction. We applied the velocity-tuned spike probabilities derived from white noise to the sequence of velocity features in the texture to construct a simulated texture response. The close match between the simulated and real responses indicates that texture coding originates in the selectivity of neurons to elemental kinetic events.},
author = {Arabzadeh, Ehsan and Zorzin, Erik and Diamond, Mathew E.},
doi = {10.1371/journal.pbio.0030017},
file = {:Users/chengxuz/Documents/journal.pbio.0030017.PDF:PDF},
isbn = {15457885},
issn = {15449173},
journal = {PLoS Biology},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {1},
pmid = {15660157},
title = {{Neuronal encoding of texture in the whisker sensory pathway}},
volume = {3},
year = {2005}
}
@article{OConnor2010,
abstract = {Classical studies have related the spiking of selected neocortical neurons to behavior, but little is known about activity sampled from the entire neural population. We recorded from neurons selected independent of spiking, using cell-attached recordings and two-photon calcium imaging, in the barrel cortex of mice performing an object localization task. Spike rates varied across neurons, from silence to {\textgreater}60 Hz. Responses were diverse, with some neurons showing large increases in spike rate when whiskers contacted the object. Nearly half the neurons discriminated object location; a small fraction of neurons discriminated perfectly. More active neurons were more discriminative. Layer (L) 4 and L5 contained the highest fractions of discriminating neurons (???63{\%} and 79{\%}, respectively), but a few L2/3 neurons were also highly discriminating. Approximately 13,000 spikes per activated barrel column were available to mice for decision making. Coding of object location in the barrel cortex is therefore highly redundant. ?? 2010 Elsevier Inc.},
author = {O'Connor, Daniel H. and Peron, Simon P. and Huber, Daniel and Svoboda, Karel},
doi = {10.1016/j.neuron.2010.08.026},
file = {:Users/chengxuz/Documents/1-s2.0-S0896627310006367-main.pdf:pdf},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {6},
pages = {1048--1061},
pmid = {20869600},
publisher = {Elsevier Inc.},
title = {{Neural activity in barrel cortex underlying vibrissa-based object localization in mice}},
url = {http://dx.doi.org/10.1016/j.neuron.2010.08.026},
volume = {67},
year = {2010}
}
@article{Knutsen2006,
abstract = {Using their large mystacial vibrissas, rats perform a variety of tasks, including localization and identification of objects. We report on the discriminatory thresholds and behavior of rats trained in a horizontal object localization task. Using an adaptive training procedure, rats learned to discriminate offsets in horizontal (anteroposterior) location with all, one row, or one arc of whiskers intact, but not when only a single whisker (C2) was intact on each cheek. However, rats initially trained with multiple whiskers typically improved when retested later with a single whisker intact. Individual rats reached localization thresholds as low as 0.24 mm (approximately 1 degree). Among the tested groups, localization acuity was finest ({\textless}1.5 mm) with rats that were initially trained with all whiskers and then trimmed to one arc of whiskers intact. Horizontal acuity was finer than the typical inter-vibrissal spacing (approximately 4.8 mm at contact points). Performance correlated with the net whisking spectral power in the range of 5-25 Hz but not in nonwhisking range of 30-50 Hz. Lesioning the facial motor nerves reduced performance to chance level. We conclude that horizontal object localization in the rat vibrissal system can reach hyperacuity level and is an active sensing process: whisker movements are both required and beneficiary, in a graded manner, for making accurate positional judgments.},
author = {Knutsen, Per Magne and Pietr, Maciej and Ahissar, Ehud},
doi = {10.1523/JNEUROSCI.1516-06.2006},
file = {:Users/chengxuz/Documents/8451.full.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Animals,Discrimination (Psychology),Discrimination (Psychology): physiology,Discrimination Learning,Discrimination Learning: physiology,Head Movements,Head Movements: physiology,Male,Movement,Movement: physiology,Rats,Rats: physiology,Rats: psychology,Sensation,Sensation: physiology,Time Factors,Vibrissae,Vibrissae: physiology,Wistar},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {33},
pages = {8451--64},
pmid = {16914670},
title = {{Haptic object localization in the vibrissal system: behavior and performance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16914670},
volume = {26},
year = {2006}
}
@article{Petersen2007,
abstract = {The tactile somatosensory pathway from whisker to cortex in rodents provides a well-defined system for exploring the link between molecular mechanisms, synaptic circuits, and behavior. The primary somatosensory cortex has an exquisite somatotopic map where each individual whisker is represented in a discrete anatomical unit, the "barrel," allowing precise delineation of functional organization, development, and plasticity. Sensory information is actively acquired in awake behaving rodents and processed differently within the barrel map depending upon whisker-related behavior. The prominence of state-dependent cortical sensory processing is likely to be crucial in our understanding of active sensory perception, experience-dependent plasticity and learning.},
author = {Petersen, Carl C.H.},
doi = {10.1016/j.neuron.2007.09.017},
file = {:Users/chengxuz/Documents/1-s2.0-S0896627307007155-main.pdf:pdf},
isbn = {0896-6273 (Print) 0896-6273 (Linking)},
issn = {0896-6273},
journal = {Neuron},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {2},
pages = {339--355},
pmid = {17964250},
title = {{The Functional Organization of the Barrel Cortex}},
url = {http://www.sciencedirect.com/science/article/B6WSS-4PYY823-F/2/67ae434b2fb155014fc3fd2fbb922275$\backslash$nhttp://www.sciencedirect.com/science?{\_}ob=ArticleURL{\&}{\_}udi=B6WSS-4PYY823-F{\&}{\_}user=127492{\&}{\_}coverDate=10/25/2007{\&}{\_}rdoc=13{\&}{\_}fmt=high{\&}{\_}orig=browse{\&}{\_}origin=browse},
volume = {56},
year = {2007}
}
@article{Umilta2007,
abstract = {To understand the relative contributions of primary motor cortex (M1) and area F5 of the ventral premotor cortex (PMv) to visually guided grasp, we made simultaneous multiple electrode recordings from the hand representations of these two areas in two adult macaque monkeys. The monkeys were trained to fixate, reach out and grasp one of six objects presented in a pseudorandom order. In M1 326 task-related neurons, 104 of which were identified as pyramidal tract neurons, and 138 F5 neurons were analyzed as separate populations. All three populations showed activity that distinguished the six objects grasped by the monkey. These three populations responded in a manner that generalized across different sets of objects. F5 neurons showed object/grasp related tuning earlier than M1 neurons in the visual presentation and premovement periods. Also F5 neurons generally showed a greater preference for particular objects/grasps than did M1 neurons. F5 neurons remained tuned to a particular grasp throughout both the premovement and reach-to-grasp phases of the task, whereas M1 neurons showed different selectivity during the different phases. We also found that different types of grasp appear to be represented by different overall levels of activity within the F5-M1 circuit. Altogether these properties are consistent with the notion that F5 grasping-related neurons play a role in translating visual information about the physical properties of an object into the motor commands that are appropriate for grasping, and which are elaborated within M1 for delivery to the appropriate spinal machinery controlling hand and digit muscles.},
author = {Umilta, M A and Brochier, T and Spinks, R L and Lemon, R N},
doi = {10.1152/jn.01094.2006},
file = {:Users/chengxuz/Documents/488.full.pdf:pdf},
isbn = {0022-3077 (Print)$\backslash$r0022-3077 (Linking)},
issn = {0022-3077},
journal = {Journal of neurophysiology},
mendeley-groups = {Ph.D related,Ph.D related/fyp{\_}related},
number = {1},
pages = {488--501},
pmid = {17329624},
title = {{Simultaneous recording of macaque premotor and primary motor cortex neuronal populations reveals different functional contributions to visuomotor grasp.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17329624},
volume = {98},
year = {2007}
}

@article{Pons1987,
abstract = {Removal of the representation of a specific body part in the postcentral cortex of the macaque resulted in the somatic deactivation of the corresponding body part in the second somatosensory area. In contrast, removal of the entire second somatosensory area had no grossly detectable effect on the somatic responsivity of neurons in the postcentral cortex. This direct electrophysiological evidence for serial cortical processing in somesthesia is similar to that found earlier for vision and, taken together with recent anatomical evidence, suggests that there is a common cortical plan for the processing of sensory information in the various sensory modalities.},
author = {Pons, T P and Garraghty, P E and Friedman, David P and Mishkin, Mortimer},
doi = {10.1126/science.3603028},
file = {:Users/chengxuz/Documents/417.full.pdf:pdf},
isbn = {0036-8075 (Print)},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
mendeley-groups = {Ph.D related/fyp{\_}related},
number = {4813},
pages = {417--420},
pmid = {3603028},
title = {{Physiological evidence for serial processing in somatosensory cortex.}},
volume = {237},
year = {1987}
}

@article{Inui2004,
abstract = {Although numerous anatomical and electrophysiological findings in animal studies have supported a hierarchical scheme of somatosensory processing, precise activation timings of each cortical area are not known. Therefore we examined the temporal relationship of activities among multiple cortical areas using magnetoencephalography in humans. We found activations in Brodmann's areas 3b, 4, 1, 5 and the secondary somatosensory cortex region in the right hemisphere following transcutaneous electrical stimulation of the dorsum of the left hand. The mean onset latencies of each cortical activity were 14.4, 14.5, 18.0, 22.4 and 21.7 ms, respectively. The differences of onset latencies among these activations indicated the serial mode of processing both through the postcentral gyrus and through the primary and secondary somatosensory cortices.},
author = {Inui, Koji and Wang, Xiaohong and Tamura, Yohei and Kaneoke, Yoshiki and Kakigi, Ryusuke},
doi = {10.1093/cercor/bhh043},
file = {:Users/chengxuz/Documents/Cereb. Cortex-2004-Inui-851-7.pdf:pdf},
isbn = {1047-3211},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {Cortex,Human,Serial processing,Somatosensory system},
mendeley-groups = {Ph.D related/fyp{\_}related},
number = {8},
pages = {851--857},
pmid = {15054058},
title = {{Serial processing in the human somatosensory system}},
volume = {14},
year = {2004}
}

@article{Hubel1959,
    abstract = {Recordings were made in lightly anaesthesized cats whose retinas were stimulated, singly or together, with light spots of various sizes and shapes. Receptive fields, defined as restricted areas where illumination influenced the firing of a single cortical unit, usually contained mutually antagonistic excitatory and inhibitory regions. Thus a stimulus covering a whole field was relatively ineffective in driving most units. Effective driving of a unit required a stimulus specific in form, size, position, and orientation; based on the arrangement of excitatory and inhibitory areas. About 20{\%} of the cortical units studied could be activated from either eye; these were driven from roughly homologous regions of the retinas and summation and antagonism could be shown. (PsycINFO Database Record (c) 2009 APA, all rights reserved)},
    author = {Hubel, D H and Wiesel, T N},
    doi = {10.1113/jphysiol.2009.174151},
    file = {:Users/chengxuz/Documents/tjp19591483574.pdf:pdf},
    isbn = {0022-3751 (Print)},
    issn = {00223751},
    journal = {Journal of Physiology},
    keywords = {CEREBRAL CORTEX/physiology,NEURONS/physiology},
    mendeley-groups = {Ph.D related/fyp{\_}related},
    pages = {574--591},
    pmid = {14403679},
    title = {{Receptive fields of single neurones in the cat's striate cortex.}},
    url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed{\&}id=14403679{\&}retmode=ref{\&}cmd=prlinks},
    volume = {148},
    year = {1959}
}

@article{Krizhevsky,
    abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
    archivePrefix = {arXiv},
    arxivId = {1102.0183},
    author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
    doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
    eprint = {1102.0183},
    file = {:Users/chengxuz/Library/Application Support/Mendeley Desktop/Downloaded/Krizhevsky, Hinton - Unknown - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
    isbn = {9781627480031},
    issn = {10495258},
    journal = {Advances In Neural Information Processing Systems},
    mendeley-groups = {Sign of Vision},
    pages = {1--9},
    pmid = {7491034},
    title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
    year = {2012}
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={82--97},
  year={2012},
  publisher={IEEE}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{Yamins2013,
    abstract = {Search Machine Learning Repository: Hierarchical  Modular  Optimization of Convolutional Networks  Achieves  Representations  Similar to Macaque IT and Human  Ventral  Stream Authors: Daniel L. Yamins, Ha Hong, Charles Cadieu and James J. Dicarlo Conference: Advances ... $\backslash$n},
    author = {Yamins, D L and Hong, H and Cadieu, C},
    file = {:Users/chengxuz/Library/Application Support/Mendeley Desktop/Downloaded/Yamins, Hong, Cadieu - 2013 - Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT.pdf:pdf},
    journal = {Advances in neural information processing systems},
    mendeley-groups = {pub of DiCarlo},
    pages = {1--9},
    title = {{Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream}},
    url = {http://machinelearning.wustl.edu/mlpapers/papers/NIPS2013{\_}4991$\backslash$npapers3://publication/uuid/E90976F4-5E4C-482D-B785-561E5A45B9D2},
    year = {2013}
}
@article{Yamins2014,
    abstract = {The ventral visual stream underlies key human visual object recognition abilities. However, neural encoding in the higher areas of the ventral stream remains poorly understood. Here, we describe a modeling approach that yields a quantitatively accurate model of inferior temporal (IT) cortex, the highest ventral cortical area. Using high-throughput computational techniques, we discovered that, within a class of biologically plausible hierarchical neural network models, there is a strong correlation between a model's categorization performance and its ability to predict individual IT neural unit response data. To pursue this idea, we then identified a high-performing neural network that matches human performance on a range of recognition tasks. Critically, even though we did not constrain this model to match neural data, its top output layer turns out to be highly predictive of IT spiking responses to complex naturalistic images at both the single site and population levels. Moreover, the model's intermediate layers are highly predictive of neural responses in the V4 cortex, a midlevel visual area that provides the dominant cortical input to IT. These results show that performance optimization-applied in a biologically appropriate model class-can be used to build quantitative predictive models of neural processing.},
    author = {Yamins, Daniel L K and Hong, Ha and Cadieu, Charles F and Solomon, Ethan a and Seibert, Darren and DiCarlo, James J},
    doi = {10.1073/pnas.1403112111},
    file = {:Users/chengxuz/Library/Application Support/Mendeley Desktop/Downloaded/Yamins et al. - 2014 - Performance-optimized hierarchical models predict neural responses in higher visual cortex.pdf:pdf},
    issn = {1091-6490},
    journal = {Proceedings of the National Academy of Sciences of the United States of America},
    mendeley-groups = {pub of DiCarlo,Sign of Vision},
    month = {jun},
    number = {23},
    pages = {8619--24},
    pmid = {24812127},
    title = {{Performance-optimized hierarchical models predict neural responses in higher visual cortex.}},
    url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4060707{\&}tool=pmcentrez{\&}rendertype=abstract},
    volume = {111},
    year = {2014}
}
@article{Cadieu2014,
    abstract = {The primate visual system achieves remarkable visual object recognition performance even in brief presentations, and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations, such as the amount of noise, the number of neural recording sites, and the number of trials, and computational limitations, such as the complexity of the decoding classifier and the number of classifier training examples. In this work, we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT, and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds.},
    archivePrefix = {arXiv},
    arxivId = {1406.3284},
    author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel L K and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan A. and Majaj, Najib J. and DiCarlo, James J.},
    doi = {10.1371/journal.pcbi.1003963},
    eprint = {1406.3284},
    file = {:Users/chengxuz/Library/Application Support/Mendeley Desktop/Downloaded/Cadieu et al. - Unknown - Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition.pdf:pdf},
    isbn = {1553-7358},
    issn = {15537358},
    journal = {PLoS Computational Biology},
    mendeley-groups = {Sign of Vision},
    number = {12},
    pages = {1--35},
    pmid = {25521294},
    title = {{Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition}},
    volume = {10},
    year = {2014}
}

@article{Roe2012,
abstract = {Visual area V4 is a midtier cortical area in the ventral visual pathway. It is crucial for visual object recognition and has been a focus of many studies on visual attention. However, there is no unifying view of V4's role in visual processing. Neither is there an understanding of how its role in feature processing interfaces with its role in visual attention. This review captures our current knowledge of V4, largely derived from electrophysiological and imaging studies in the macaque monkey. Based on recent discovery of functionally specific domains in V4, we propose that the unifying function of V4 circuitry is to enable selective extraction of specific functional domain-based networks, whether it be by bottom-up specification of object features or by top-down attentionally driven selection. In this Review, Roe and colleagues discuss our current knowledge of visual area V4 and propose that V4 circuitry enables selective extraction of specific functional domain-based networks to enable visual processing. ?? 2012 Elsevier Inc.},
author = {Roe, Anna W. and Chelazzi, Leonardo and Connor, Charles E. and Conway, Bevil R. and Fujita, Ichiro and Gallant, Jack L. and Lu, Haidong and Vanduffel, Wim},
doi = {10.1016/j.neuron.2012.03.011},
file = {:C$\backslash$:/Users/Chengxu/Desktop/Papers/SomePapers/Roe2012.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$r0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
mendeley-groups = {Ph.D related},
number = {1},
pages = {12--29},
pmid = {22500626},
publisher = {Elsevier Inc.},
title = {{Toward a Unified Theory of Visual Area V4}},
url = {http://dx.doi.org/10.1016/j.neuron.2012.03.011},
volume = {74},
year = {2012}
}

@article{Qiu2016,
abstract = {Computer graphics can not only generate synthetic images and ground truth but it also offers the possibility of constructing virtual worlds in which: (i) an agent can perceive, navigate, and take actions guided by AI algorithms, (ii) properties of the worlds can be modified (e.g., material and reflectance), (iii) physical simulations can be performed, and (iv) algorithms can be learnt and evaluated. But creating realistic virtual worlds is not easy. The game industry, however, has spent a lot of effort creating 3D worlds, which a player can interact with. So researchers can build on these resources to create virtual worlds, provided we can access and modify the internal data structures of the games. To enable this we created an open-source plugin UnrealCV (http://unrealcv.github.io) for a popular game engine Unreal Engine 4 (UE4). We show two applications: (i) a proof of concept image dataset, and (ii) linking Caffe with the virtual world to test deep network algorithms.},
archivePrefix = {arXiv},
arxivId = {1609.01326},
author = {Qiu, Weichao and Yuille, Alan},
eprint = {1609.01326},
file = {:C$\backslash$:/Users/Chengxu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu, Yuille - 2016 - UnrealCV Connecting Computer Vision to Unreal Engine.pdf:pdf},
mendeley-groups = {Ph.D related},
pages = {1--8},
title = {{UnrealCV: Connecting Computer Vision to Unreal Engine}},
url = {http://arxiv.org/abs/1609.01326},
year = {2016}
}

@article{Johnson-Roberson2016,
abstract = {Deep learning has rapidly transformed the state of the art algorithms used to address a variety of problems in computer vision and robotics. These breakthroughs have however relied upon massive amounts of human annotated training data. This time-consuming process has begun impeding the progress of these deep learning efforts. This paper describes a method to incorporate photo-realistic computer images from a simulation engine to rapidly generate annotated data that can be used for training of machine learning algorithms. We demonstrate that a state of the art architecture, which is trained only using these synthetic annotations, performs better than the identical architecture trained on human annotated real-world data, when tested on the KITTI data set for vehicle detection. By training machine learning algorithms on a rich virtual world, this paper illustrates that real objects in real scenes can be learned and classified using synthetic data. This approach offers the possibility of accelerating deep learning's application to sensor based classification problems like those that appear in self-driving cars.},
archivePrefix = {arXiv},
arxivId = {1610.01983},
author = {Johnson-Roberson, Matthew and Barto, Charles and Mehta, Rounak and Sridhar, Sharath Nittur and Vasudevan, Ram},
eprint = {1610.01983},
file = {:C$\backslash$:/Users/Chengxu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson-Roberson et al. - 2016 - Driving in the Matrix Can Virtual Worlds Replace Human-Generated Annotations for Real World Tasks.pdf:pdf},
mendeley-groups = {Ph.D related},
title = {{Driving in the Matrix: Can Virtual Worlds Replace Human-Generated Annotations for Real World Tasks?}},
url = {http://arxiv.org/abs/1610.01983},
year = {2016}
}

@article{Towal2011,
abstract = {In all sensory modalities, the data acquired by the nervous system is shaped by the biomechanics, material properties, and the morphology of the peripheral sensory organs. The rat vibrissal (whisker) system is one of the premier models in neuroscience to study the relationship between physical embodiment of the sensor array and the neural circuits underlying perception. To date, however, the three-dimensional morphology of the vibrissal array has not been characterized. Quantifying array morphology is important because it directly constrains the mechanosensory inputs that will be generated during behavior. These inputs in turn shape all subsequent neural processing in the vibrissal-trigeminal system, from the trigeminal ganglion to primary somatosensory ("barrel") cortex. Here we develop a set of equations for the morphology of the vibrissal array that accurately describes the location of every point on every whisker to within ¡À5//{\%} of the whisker length. Given only a whisker's identity (row and column location within the array), the equations establish the whisker's two-dimensional (2D) shape as well as three-dimensional (3D) position and orientation. The equations were developed via parameterization of 2D and 3D scans of six rat vibrissal arrays, and the parameters were specifically chosen to be consistent with those commonly measured in behavioral studies. The final morphological model was used to simulate the contact patterns that would be generated as a rat uses its whiskers to tactually explore objects with varying curvatures. The simulations demonstrate that altering the morphology of the array changes the relationship between the sensory signals acquired and the curvature of the object. The morphology of the vibrissal array thus directly constrains the nature of the neural computations that can be associated with extraction of a particular object feature. These results illustrate the key role that the physical embodiment of the sensor array plays in the sensing process. ------------------------------------- Whisker mechanics Very extensive and boring description of whiskers. Simulation of whisker contact during whisking with objects displaying different curvature.},
author = {Towal, R. Blythe and Quist, Brian W. and Gopal, Venkatesh and Solomon, Joseph H. and Hartmann, Mitra J Z},
doi = {10.1371/journal.pcbi.1001120},
file = {:C$\backslash$:/Users/Chengxu/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Towal et al. - 2011 - The morphology of the rat vibrissal array A model for quantifying spatiotemporal patterns of whisker-object contac.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
mendeley-groups = {Ph.D related},
number = {4},
pmid = {21490724},
title = {{The morphology of the rat vibrissal array: A model for quantifying spatiotemporal patterns of whisker-object contact}},
volume = {7},
year = {2011}
}

@article{Quist2014,
abstract = {During exploratory behavior, rats brush and tap their whiskers against objects, and the mechanical signals so generated constitute the primary sensory variables upon which these animals base their vibrissotactile perception of the world. To date, however, we lack a general dynamic model of the vibrissa that includes the effects of inertia, damping, and collisions. We simulated vibrissal dynamics to compute the time-varying forces and bending moment at the vibrissa base during both noncontact (free-air) whisking and whisking against an object (collision). Results show the following: (1) during noncontact whisking, mechanical signals contain components at both the whisking frequency and also twice the whisking frequency (the latter could code whisking speed); (2) when rats whisk rhythmically against an object, the intrinsic dynamics of the vibrissa can be as large as many of the mechanical effects of the collision, however, the axial force could still generate responses that reliably indicate collision based on thresholding; and (3) whisking velocity will have only a small effect on the transient response generated during a whisker-object collision. Instead, the transient response will depend in large part on how the rat chooses to decelerate its vibrissae after the collision. The model allows experimentalists to estimate error bounds on quasi-static descriptions of vibrissal shape, and its predictions can be used to bound realistic expectations from neurons that code vibrissal sensing. We discuss the implications of these results under the assumption that primary sensory neurons of the trigeminal ganglion are sensitive to various combinations of mechanical signals.},
author = {Quist, Brian W and Seghete, Vlad and Huet, Lucie A and Murphey, Todd D and Hartmann, Mitra J Z},
doi = {10.1523/JNEUROSCI.1707-12.2014},
file = {:C$\backslash$:/Users/Chengxu/Desktop/Papers/SomePapers/quist{\_}jneurosci{\_}2014.pdf:pdf},
isbn = {0270-6474},
issn = {1529-2401},
journal = {J Neurosci},
mendeley-groups = {Ph.D related},
number = {30},
pages = {9828--9844},
pmid = {25057187},
title = {{Modeling Forces and Moments at the Base of a Rat Vibrissa during Noncontact Whisking and Whisking against an Object.}},
url = {http://dx.doi.org/10.1523/JNEUROSCI.1707-12.2014},
volume = {34},
year = {2014}
}
@article{Huet2016,
author = {Huet, Lucie A. and Hartmann, Mitra J Z},
doi = {10.1109/TOH.2016.2522432},
file = {:C$\backslash$:/Users/Chengxu/Desktop/Papers/SomePapers/b64044f79f41703f5a90dcf47585d666d7b2.pdf:pdf},
issn = {19391412},
journal = {IEEE Transactions on Haptics},
keywords = {Rat,biomechanics,friction,neuroscience,tactile,trigeminal,trigeminal ganglion,whisker,whisker mechanics},
mendeley-groups = {Ph.D related},
number = {2},
pages = {158--169},
title = {{Simulations of a Vibrissa Slipping along a Straight Edge and an Analysis of Frictional Effects during Whisking}},
volume = {9},
year = {2016}
}

@misc{unity, title={Unity homepage, https://unity3d.com/}, url={https://unity3d.com/}, journal={Unity}, publisher={Unity Technologies}}

@article{Chang2015,
    abstract = {We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects. ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy. It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations. Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision. At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets). In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans.},
    archivePrefix = {arXiv},
    arxivId = {1512.03012},
    author = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
    eprint = {1512.03012},
    file = {:Users/chengxuz/Documents/1512.03012v1.pdf:pdf},
    journal = {ArXiv},
    mendeley-groups = {Ph.D related/fyp{\_}related},
    title = {{ShapeNet: An Information-Rich 3D Model Repository}},
    url = {http://arxiv.org/abs/1512.03012},
    year = {2015}
}

@misc{dosch, title={Dosch homepage, https://www.doschdesign.com/}, url={https://www.doschdesign.com/}, journal={Dosch}, publisher={Dosch Design}}

@article{Hadap2008,
    author = {Hadap, Sunil and Cani, Marie-Paule and Lin, Ming and Kim, Tae-Yong and Bertails, Florence and Marschner, Steve and Ward, Kelly and Ka{\v{c}}i-Alesi, Zoran},
    file = {:Users/chengxuz/Documents/finalcoursenotes2008.pdf:pdf},
    mendeley-groups = {Ph.D related/fyp{\_}related},
    title = {{Realistic Hair Simulation Animation and Rendering}},
    year = {2008}
}
@article{Ward2007,
    abstract = {Realistic hair modeling is a fundamental part of creating virtual humans in computer graphics. This paper surveys the state of the art in the major topics of hair modeling: hairstyling, hair simulation, and hair rendering. Because of the difficult, often unsolved problems that arise in all these areas, a broad diversity of approaches are used, each with strengths that make it appropriate for particular applications. We discuss each of these major topics in turn, presenting the unique challenges facing each area and describing solutions that have been presented over the years to handle these complex issues. Finally, we outline some of the remaining computational challenges in hair modeling.},
    author = {Ward, Kelly and Bertails, Florence and Kim, Tae Yong and Marschner, Stephen R. and Cani, Marie Paule and Lin, Ming C.},
    doi = {10.1109/TVCG.2007.30},
    file = {:Users/chengxuz/Documents/WBKMCL07.pdf:pdf},
    isbn = {1077-2626},
    issn = {10772626},
    journal = {IEEE Transactions on Visualization and Computer Graphics},
    keywords = {Collision handling,Hair modeling,Hardware rendering,Light scattering,Physically-based simulation,User interaction},
    mendeley-groups = {Ph.D related/fyp{\_}related},
    number = {2},
    pages = {213--233},
    pmid = {17218740},
    title = {{A survey on hair modeling: Styling, simulation, and rendering}},
    volume = {13},
    year = {2007}
}

@misc{ wiki:bullet,
author = "Wikipedia",
title = "Bullet (software) --- Wikipedia{,} The Free Encyclopedia",
year = "2016",
url = "https://en.wikipedia.org/w/index.php?title=Bullet_(software)&oldid=745094110",
note = "[Online; accessed 19-October-2016]"
}

@article{ purves2001neuroscience,
  title={Neuroscience},
  author={Purves, Dale and Augustine, George J and Fitzpatrick, David and Katz, Lawrence C and LaMantia, Anthony-Samuel and McNamara, James O and Williams, S Mark},
  journal={Sunderland, MA: Sinauer Associates},
  volume={3},
  year={2001}
}
